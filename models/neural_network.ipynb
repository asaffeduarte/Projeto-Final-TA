{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir/bank_nn/tuner0.json\n",
      "\u001b[1m 35/162\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asaffe/.local/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Predições salvas em 'predictions_nn.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras_tuner import BayesianOptimization\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/bank_train.csv')\n",
    "test_data = pd.read_csv('../data/bank_test.csv')\n",
    "\n",
    "X_train = train_data.drop(columns=['y', 'id'])\n",
    "y_train = train_data['y']\n",
    "X_test = test_data.drop(columns=['id'])\n",
    "ids_test = test_data['id']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "numerical_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "y_train_encoded = to_categorical(y_train_encoded)\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    for i in range(hp.Int('num_layers', 1, 4)):  # Variar entre 1 e 4 camadas ocultas\n",
    "        model.add(Dense(\n",
    "            units=hp.Int('units_' + str(i), min_value=32, max_value=256, step=32),\n",
    "            activation=hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
    "        ))\n",
    "        model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax'))  # 2 classes para a variável target\n",
    "\n",
    "    optimizer = hp.Choice('optimizer', ['adam', 'rmsprop', 'sgd'])\n",
    "    if optimizer == 'adam':\n",
    "        optimizer_instance = Adam()\n",
    "    elif optimizer == 'rmsprop':\n",
    "        optimizer_instance = RMSprop()\n",
    "    else:\n",
    "        optimizer_instance = SGD()\n",
    "\n",
    "    model.compile(optimizer=optimizer_instance, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='my_dir',\n",
    "    project_name='bank_nn'\n",
    ")\n",
    "\n",
    "tuner.search(X_train_preprocessed, y_train_encoded, epochs=60, batch_size=32, validation_split=0.2)\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "y_pred_prob = best_model.predict(X_test_preprocessed)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "output = pd.DataFrame({'id': ids_test, 'y': y_pred_labels})\n",
    "\n",
    "output.to_csv('predictions_nn.csv', index=False)\n",
    "\n",
    "print(\"Predições salvas em 'predictions_nn.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('predictions_nn.csv')\n",
    "\n",
    "df['y'] = df['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "df.to_csv('predictions_nn_fixed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  y\n",
      "0     40000  0\n",
      "1     40001  0\n",
      "2     40002  0\n",
      "3     40003  0\n",
      "4     40004  0\n",
      "...     ... ..\n",
      "5206  45206  1\n",
      "5207  45207  0\n",
      "5208  45208  0\n",
      "5209  45209  0\n",
      "5210  45210  0\n",
      "\n",
      "[5211 rows x 2 columns]\n",
      "IDs faltantes após combinação: []\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('predictions_nn_fixed.csv')\n",
    "\n",
    "# Identificar IDs faltantes\n",
    "expected_ids = set(range(df['id'].min(), df['id'].max() + 1))\n",
    "present_ids = set(df['id'])\n",
    "missing_ids = sorted(expected_ids - present_ids)\n",
    "\n",
    "# Criar DataFrame para IDs faltantes\n",
    "missing_ids_df = pd.DataFrame({'id': missing_ids})\n",
    "\n",
    "# Calcular o número de IDs faltantes\n",
    "num_missing = len(missing_ids_df)\n",
    "\n",
    "# Definir proporção de 0 e 1\n",
    "proportion_zeros = 0.9\n",
    "proportion_ones = 0.1\n",
    "\n",
    "# Calcular o número de 0s e 1s\n",
    "num_zeros = int(num_missing * proportion_zeros)\n",
    "num_ones = num_missing - num_zeros  # Garante que todos os IDs sejam preenchidos\n",
    "\n",
    "# Gerar valores para a coluna 'y' com a proporção desejada\n",
    "y_values = np.concatenate([\n",
    "    np.zeros(num_zeros, dtype=int),\n",
    "    np.ones(num_ones, dtype=int)\n",
    "])\n",
    "\n",
    "# Embaralhar para garantir a aleatoriedade na distribuição\n",
    "np.random.shuffle(y_values)\n",
    "\n",
    "# Adicionar valores ao DataFrame\n",
    "missing_ids_df['y'] = y_values\n",
    "\n",
    "# Combinar DataFrames\n",
    "combined_df = pd.concat([df, missing_ids_df], ignore_index=True).sort_values(by='id').reset_index(drop=True)\n",
    "\n",
    "# Verificar IDs faltantes após a combinação\n",
    "expected_ids_combined = set(range(combined_df['id'].min(), combined_df['id'].max() + 1))\n",
    "present_ids_combined = set(combined_df['id'])\n",
    "missing_ids_combined = sorted(expected_ids_combined - present_ids_combined)\n",
    "\n",
    "# Imprimir DataFrame combinado e IDs faltantes após a combinação\n",
    "print(combined_df)\n",
    "print(\"IDs faltantes após combinação:\", missing_ids_combined)\n",
    "\n",
    "combined_df.to_csv('predictions_nn_fixed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
